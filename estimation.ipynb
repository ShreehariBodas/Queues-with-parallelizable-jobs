{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a259b9c5-a1f3-4be9-ba06-1e466e79fdc1",
   "metadata": {},
   "source": [
    "## Estimating $p_1, p_2$ in queues with parallelizable jobs\n",
    "\n",
    "### $\\circ$ Arrival rate $\\lambda$\n",
    "### $\\circ$ Job sizes $\\sim \\text{Exp}(\\mu)$\n",
    "### $\\circ$ $c$ cores\n",
    "### $\\circ$ Incoming jobs - speed-up $s_1(.)$ or $s_2(.)$ parameterized by $p_1, p_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fbc80-8374-44c9-b740-e60f9bfca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from scipy.integrate import quad\n",
    "# from scipy import linspace, meshgrid, arange, empty, concatenate, newaxis, shape\n",
    "from numpy import linspace, meshgrid, arange, empty, concatenate, newaxis, shape\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d5c875-8d83-4907-9ded-21d88d28dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_service_times(mu, n):\n",
    "    service_times = np.random.exponential(1/mu, n)\n",
    "    return service_times\n",
    "\n",
    "def generate_arrival_times(lam, n):\n",
    "    interarrival_times = np.random.exponential(1/lam, n-1)\n",
    "    arrival_times = np.append([0], np.cumsum(interarrival_times))\n",
    "    return arrival_times\n",
    "\n",
    "def generate_job_categories(alpha, n):\n",
    "    job_categories = np.ones(n) + np.random.binomial(1, alpha, n)\n",
    "    return job_categories\n",
    "\n",
    "def allocate_cores(total_cores, n_jobs):\n",
    "# This function should come from a learning process\n",
    "# For now, we assume a simple allocation policy so we can study estimation\n",
    "    if n_jobs[0] == 0 and n_jobs[1] == 0:\n",
    "        return np.array([0, 0])\n",
    "    elif n_jobs[0] == 0:\n",
    "        return np.array([0, total_cores])\n",
    "    elif n_jobs[1] == 0:\n",
    "        return np.array([total_cores, 0])\n",
    "    else:\n",
    "        fraction = n_jobs[0]/(n_jobs[0] + n_jobs[1])\n",
    "        allocation = np.array([fraction*total_cores, (1-fraction)*total_cores])\n",
    "    return allocation\n",
    "\n",
    "def speed_up(amdahl_par, n_cores):\n",
    "    speed_up = 1/(1 - amdahl_par*(1 - 1/max(1, n_cores)))\n",
    "    return speed_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc0849e-eeea-4e5f-89bb-575a62fabeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    # Essential characteristics of each job which we would like to track\n",
    "    def __init__(self):\n",
    "        self.identity = 0\n",
    "        self.category = int(0)\n",
    "        self.arrival_time = 0\n",
    "        self.departure_time = 0\n",
    "        self.service_time = 0\n",
    "        self.residual_service_time = 0\n",
    "        self.history = [] # List of 2-tuple elements (speed, time at that speed)\n",
    "\n",
    "\n",
    "def queue_simulation(amdahl_pars, model_pars, n, arrival_times, service_times, job_categories, initial_state):\n",
    "    \n",
    "    # Unpack model variables\n",
    "    lam = model_pars[0]\n",
    "    mu = model_pars[1]\n",
    "    total_cores = model_pars[2]\n",
    "    alpha = model_pars[3]\n",
    "    \n",
    "    # Preprocessing\n",
    "    jobs = [Job() for i in range(n)]\n",
    "    for i in range(n):\n",
    "        jobs[i].identity = i\n",
    "        jobs[i].category = job_categories[i]\n",
    "        jobs[i].arrival_time = arrival_times[i]\n",
    "        jobs[i].service_time = service_times[i]\n",
    "        jobs[i].residual_service_time = service_times[i]\n",
    "    \n",
    "    ##############################################################################################################################################################\n",
    "    \n",
    "    # Data required for future\n",
    "    events = [] # List of 3-element tuples (Time, Arrival/Departure, Job id)\n",
    "    n_jobs_in_system_just_after_events = [] # List of 2-element tuples (Number of Type 1 jobs, Number of Type 2 jobs)\n",
    "    core_allocation_just_after_events = [] # List of 2-element tuples (Number of Type 1 cores, Number of Type 2 cores)\n",
    "    \n",
    "    # Simulation variables\n",
    "    job_ids_in_system = [] # Dynamic list which stores indices of jobs in system at any given time \n",
    "    arrived_job_id = -1\n",
    "    departed_job_id = -1\n",
    "    event = 'arrival'\n",
    "    n_jobs_in_system = initial_state\n",
    "    current_core_allocation = np.zeros(2)\n",
    "    current_core_allocation_per_job = np.zeros(2)\n",
    "    \n",
    "    current_time = 0\n",
    "    time_until_next_arrival = 0\n",
    "    time_until_next_departure = 0\n",
    "    time_until_next_event = 0\n",
    "    speed_up_values = np.zeros(2)\n",
    "    \n",
    "    ##############################################################################################################################################################\n",
    "    \n",
    "    # Queue simulation\n",
    "    while arrived_job_id < n-1:\n",
    "        if event == 'arrival':\n",
    "            arrived_job_id += 1 \n",
    "            events.append([current_time, 'arrival', arrived_job_id])\n",
    "            job_ids_in_system.append(arrived_job_id) # Appends arrived job id to the list of jobs in system\n",
    "            n_jobs_in_system[int(jobs[arrived_job_id].category)-1] += 1\n",
    "        else:\n",
    "            events.append([current_time, 'departure', departed_job_id])\n",
    "            job_ids_in_system.remove(departed_job_id) # Removes departed job id from list of jobs in system\n",
    "            n_jobs_in_system[int(jobs[departed_job_id].category)-1] -= 1\n",
    "        \n",
    "        n_jobs_in_system_just_after_events.append(n_jobs_in_system.copy())\n",
    "        current_core_allocation = allocate_cores(total_cores, n_jobs_in_system)\n",
    "        core_allocation_just_after_events.append(current_core_allocation)\n",
    "        current_core_allocation_per_job = np.array([current_core_allocation[j]/n_jobs_in_system[j] if n_jobs_in_system[j] !=0 else 0 for j in range(2)])\n",
    "        \n",
    "        if arrived_job_id != n-1:\n",
    "            # Time until next arrival\n",
    "            time_until_next_arrival = arrival_times[arrived_job_id + 1] - current_time\n",
    "            # Time until next departure\n",
    "            if job_ids_in_system == []:\n",
    "                time_until_next_departure = math.inf\n",
    "            else:\n",
    "                speed_up_values[0] = speed_up(amdahl_pars[0], current_core_allocation_per_job[0])\n",
    "                speed_up_values[1] = speed_up(amdahl_pars[1], current_core_allocation_per_job[1])\n",
    "                expected_times_until_departure = np.array([jobs[i].residual_service_time/speed_up_values[int(jobs[i].category)-1] for i in job_ids_in_system])\n",
    "                time_until_next_departure = np.min(expected_times_until_departure)\n",
    "            # Time until next event\n",
    "            if time_until_next_arrival > time_until_next_departure:\n",
    "                event = 'departure'\n",
    "                time_until_next_event = time_until_next_departure\n",
    "                departed_job_id = job_ids_in_system[np.argmin(expected_times_until_departure)]\n",
    "                jobs[departed_job_id].departure_time = current_time + time_until_next_event\n",
    "            else:\n",
    "                event = 'arrival'\n",
    "                time_until_next_event = time_until_next_arrival\n",
    "            \n",
    "            # Updating system state at time of next event\n",
    "            for job_id in job_ids_in_system:\n",
    "                jobs[job_id].residual_service_time -= speed_up_values[int(jobs[job_id].category)-1] * time_until_next_event\n",
    "                state = [speed_up_values[int(jobs[job_id].category)-1], time_until_next_event]\n",
    "                jobs[job_id].history.append(list(state))\n",
    "            \n",
    "            current_time += time_until_next_event\n",
    "    \n",
    "    return [jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c71fc3-bbe3-4578-979d-664c9385294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given initial state of system, generates queueing dataset\n",
    "# Will be useful for us in every window\n",
    "\n",
    "def generate_dataset(amdahl_pars, model_pars, n, initial_state):\n",
    "    arrival_times = generate_arrival_times(lam, n)\n",
    "    service_times = generate_service_times(mu, n)\n",
    "    job_categories = generate_job_categories(alpha, n)\n",
    "    \n",
    "    dataset = queue_simulation(amdahl_pars, model_pars, n, arrival_times, service_times, job_categories, initial_state)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beee351-4c1a-4278-add3-10e9c56a13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_Likelihood(amdahl_pars, model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events):\n",
    "    # print(amdahl_pars)\n",
    "    \n",
    "    lam = model_pars[0]\n",
    "    mu = model_pars[1]\n",
    "    total_cores = model_pars[2]\n",
    "    alpha = model_pars[3]\n",
    "    \n",
    "    LL = 0\n",
    "    \n",
    "    # For parameter p_1\n",
    "    start_event_index = 0\n",
    "    end_event_index = 0\n",
    "    \n",
    "    while end_event_index < len(events):\n",
    "        # Calculate start index, end index for parameter p_1\n",
    "        # Corresponds basically to an inter-departure time barring edge cases\n",
    "        \n",
    "        # Start index calculation        \n",
    "        start_event_index = end_event_index\n",
    "        while start_event_index < len(events) - 1 and n_jobs_in_system_just_after_events[start_event_index][0] == 0:\n",
    "            start_event_index += 1\n",
    "        if start_event_index >= len(events) - 1:\n",
    "            break\n",
    "        # End index calculation\n",
    "        flag = 0\n",
    "        end_event_index = start_event_index\n",
    "        while end_event_index + 1 < len(events):\n",
    "            end_event_index += 1\n",
    "            if events[end_event_index][1] == 'departure' and jobs[events[end_event_index][2]].category == 1:\n",
    "                flag = 1\n",
    "                break\n",
    "        # print(\"Type 1 job (Start index, Start time) = \", [start_event_index, events[start_event_index][0]], \" (End index, End time) = \", [end_event_index, events[end_event_index][0]])\n",
    "        \n",
    "        # Log Likelihood component corresponding to this inter-departure time\n",
    "        core_allocation_per_job = 0\n",
    "        for i in range(start_event_index, end_event_index):\n",
    "                core_allocation_per_job = core_allocation_just_after_events[i][0]/n_jobs_in_system_just_after_events[i][0] if n_jobs_in_system_just_after_events[i][0] !=0 else 0\n",
    "                LL += -mu * n_jobs_in_system_just_after_events[i][0] * speed_up(amdahl_pars[0], core_allocation_per_job) * (events[i+1][0] - events[i][0])\n",
    "        if flag == 1: # If flag = 0, event is just that during some time, number of departures are 0.\n",
    "            LL += np.log(n_jobs_in_system_just_after_events[end_event_index - 1][0]) + np.log(speed_up(amdahl_pars[0], core_allocation_per_job))\n",
    "        \n",
    "    # For parameter p_2\n",
    "    start_event_index = 0\n",
    "    end_event_index = 0\n",
    "    \n",
    "    while end_event_index < len(events):\n",
    "        # Calculate start index, end index for parameter p_2\n",
    "        # Corresponds basically to an inter-departure time barring edge cases\n",
    "        \n",
    "        # Start index calculation        \n",
    "        start_event_index = end_event_index\n",
    "        while start_event_index < len(events) - 1 and n_jobs_in_system_just_after_events[start_event_index][1] == 0:\n",
    "            start_event_index += 1\n",
    "        if start_event_index >= len(events) - 1:\n",
    "            break\n",
    "        # End index calculation\n",
    "        flag = 0\n",
    "        end_event_index = start_event_index\n",
    "        while end_event_index + 1 < len(events):\n",
    "            end_event_index += 1\n",
    "            if events[end_event_index][1] == 'departure' and jobs[events[end_event_index][2]].category == 2:\n",
    "                flag = 1\n",
    "                break\n",
    "        # print(\"Type 2 job (Start index, Start time) = \", [start_event_index, events[start_event_index][0]], \" (End index, End time) = \", [end_event_index, events[end_event_index][0]])\n",
    "        \n",
    "        # Log Likelihood component corresponding to this inter-departure time\n",
    "        core_allocation_per_job = 0\n",
    "        for i in range(start_event_index, end_event_index):\n",
    "                core_allocation_per_job = core_allocation_just_after_events[i][1]/n_jobs_in_system_just_after_events[i][1] if n_jobs_in_system_just_after_events[i][1] !=0 else 0\n",
    "                LL += -mu * n_jobs_in_system_just_after_events[i][1] * speed_up(amdahl_pars[1], core_allocation_per_job) * (events[i+1][0] - events[i][0])\n",
    "        if flag == 1: # If flag = 0, event is just that during some time, number of departures are 0.\n",
    "            LL += np.log(n_jobs_in_system_just_after_events[end_event_index - 1][1]) + np.log(speed_up(amdahl_pars[1], core_allocation_per_job))\n",
    "    \n",
    "    return -LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42e5b9-3b66-4341-9579-a44ea878d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events):\n",
    "    # Initial Estimates\n",
    "    initial_estimates = np.array([0.5, 0.5])\n",
    "    # Bounds\n",
    "    amdahl_par_bounds = [(0.001, 0.999), (0.001, 0.999)]\n",
    "    # Estimation\n",
    "    estd_amdahl_pars = minimize(Log_Likelihood, initial_estimates, method = \"L-BFGS-B\", args = (model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events), bounds = amdahl_par_bounds)\n",
    "    return estd_amdahl_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95b639-e26f-430e-99d2-dc77b1776e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executes one step algorithm.\n",
    "# We need to use this in every window\n",
    "\n",
    "def execute_algorithm_1(amdahl_pars, model_pars, n, initial_state):\n",
    "# Estimation based on the departure process = algorithm 1\n",
    "    dataset = generate_dataset(amdahl_pars, model_pars, n, initial_state)\n",
    "    estd_amdahl_pars = estimation(model_pars, *dataset)\n",
    "    return estd_amdahl_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e964c43-4e7a-4285-9093-ec84800addd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # True parameters\n",
    "\n",
    "# lam = 10 # Arrival rate\n",
    "# mu = 1 # Mean service time\n",
    "# total_cores = 20 # Total number of cores\n",
    "# alpha = 0.5 # Fraction of type 1 jobs\n",
    "# model_pars = [lam, mu, total_cores, alpha]\n",
    "\n",
    "# p_1 = 0.38 # Speed-up for type 1 jobs\n",
    "# p_2 = 0.79 # Speed-up for type 2 jobs\n",
    "# amdahl_pars = [p_1, p_2] \n",
    "\n",
    "# n = 50000 # Total number of arrivals\n",
    "\n",
    "# initial_state = np.array([0, 0])\n",
    "\n",
    "\n",
    "# estd_amdahl_pars = execute_algorithm_1(amdahl_pars, model_pars, n, initial_state)\n",
    "# print(\"True parameters = \", amdahl_pars)\n",
    "# print(\"Estimated parameters = \", estd_amdahl_pars.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ee32d-fea9-4c8f-8065-237c51fe5938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d13e-b207-495f-a856-16652fd27934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86934137-430c-4a91-8495-0b6bb1ee0ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9cfd80-3dc4-40ce-80fd-64bfdd144ba7",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301114c3-0ea0-4cfa-9605-5c4948450679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether inherent size as calculated from job history equates to true size.\n",
    "\n",
    "# for job in jobs:\n",
    "#     calculated_job_size = 0\n",
    "#     for state in job.history:\n",
    "#         calculated_job_size += state[0]*state[1]\n",
    "#     print(\"Calculated job size = \", calculated_job_size, \" , True job size = \", job.service_time)\n",
    "    \n",
    "# NOTE:\n",
    "# For some of the jobs at the end, calculated and true job sizes will not match.\n",
    "# This is because they have not yet departed from system"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
