{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155009ee-9b75-4c35-b0a0-cbb9ea0f5dde",
   "metadata": {},
   "source": [
    "## Bellman Optimality Equation solver\n",
    "### MDP Formulation:\n",
    "### $\\mathcal{S} = \\big\\{(n_1, n_2): 0 \\leq n_1, n_2 \\leq M \\big\\}$\n",
    "### $\\mathcal{A} = [0,1]$\n",
    "### Policy $\\pi: \\mathcal{S} \\mapsto \\mathcal{A}$ allocates the fraction of cores to type 1 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd15660-7a68-4525-a484-30b81524d5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from scipy.integrate import quad\n",
    "from numpy import linspace, meshgrid, arange, empty, concatenate, newaxis, shape\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a4a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_up(amdahl_par, n_cores):\n",
    "    speed_up = 1/(1 - amdahl_par*(1 - 1/max(1, n_cores)))\n",
    "    return speed_up\n",
    "\n",
    "\n",
    "# Returns transition probabilities from any state (n1, n2)\n",
    "def transition_probabilities(model_pars, state, action):\n",
    "    lam, mu, cores, p1, p2, alpha, M = model_pars\n",
    "    [n1, n2] = state\n",
    "    \n",
    "    prob_1 = lam*alpha if n1 < M else 0\n",
    "    prob_2 = lam*(1-alpha) if n2 < M else 0\n",
    "    prob_3 = min(n1, cores*action)*mu*speed_up(p1, cores*action/n1) if n1 > 0 else 0\n",
    "    prob_4 = min(n2, cores*(1-action))*mu*speed_up(p2, cores*(1-action)/n2) if n2 > 0 else 0\n",
    "    prob_5 = 1 - prob_1 - prob_2 - prob_3 - prob_4\n",
    "    return [prob_1, prob_2, prob_3, prob_4, prob_5]\n",
    "\n",
    "\n",
    "# Given current state, it samples the next state under the optimal core allocation policy\n",
    "# which is evaluated by solving the Bellman optimality equation\n",
    "def sample_next_state(model_pars, current_state, action):\n",
    "    [n1, n2] = current_state\n",
    "    \n",
    "    possible_next_states = [[n1+1, n2], [n1, n2+1], [n1-1, n2], [n1, n2-1], [n1, n2]]\n",
    "    indices = [0, 1, 2, 3, 4]\n",
    "    probabilities = transition_probabilities(model_pars, current_state, action)\n",
    "    next_state = np.array(possible_next_states[np.random.choice(indices, size = 1, p = probabilities)[0]])\n",
    "    return next_state\n",
    "\n",
    "\n",
    "# Following functions solve Bellman optimality equation\n",
    "def A(model_pars, state, V):\n",
    "    # Unpacking\n",
    "    lam, mu, cores, p1, p2, alpha, M = model_pars\n",
    "    [n1, n2] = state\n",
    "    # Calculating A\n",
    "    A_val = (n1 + n2) + \\\n",
    "            (lam*alpha*(V[n1+1, n2] - V[n1, n2]) if n1 < M else 0) + \\\n",
    "            (lam*(1-alpha)*(V[n1, n2+1] - V[n1, n2]) if n2 < M else 0)\n",
    "    return A_val\n",
    "    \n",
    "    \n",
    "def H_and_action(model_pars, state, V):\n",
    "    # Unpacking\n",
    "    lam, mu, cores, p1, p2, alpha, M = model_pars\n",
    "    [n1, n2] = state\n",
    "    \n",
    "    # Evaluating best continuous action\n",
    "    # min_cost = minimize(cost, 0.5 , method=\"L-BFGS-B\", args = (model_pars, state, V), bounds = [(0,1)])\n",
    "    # a_optimal = min_cost.x\n",
    "    # H_optimal = V[n1, n2] + float(min_cost.fun)\n",
    "    \n",
    "    # Evaluating best discrete action from [0, 1/cores, 2/cores, ..., 1]\n",
    "    costs_given_action = np.array([cost(i/cores, model_pars, state, V) for i in  range(cores+1)])\n",
    "    index = np.argmin(costs_given_action)\n",
    "    a_optimal = index/cores\n",
    "    H_optimal = V[n1, n2] + costs_given_action[index]\n",
    "    return H_optimal, a_optimal\n",
    "    \n",
    "    \n",
    "def cost(action, model_pars, state, V):\n",
    "    # Unpacking\n",
    "    lam, mu, cores, p1, p2, alpha, M = model_pars\n",
    "    [n1, n2] = state\n",
    "    # Calculating cost\n",
    "    cost = (min(n1, cores*action)*mu*speed_up(p1, cores*action/n1)*(V[n1-1, n2] - V[n1, n2]) if n1 > 0 else 0) + \\\n",
    "           (min(n2, cores*(1-action))*mu*speed_up(p2, cores*(1-action)/n2)*(V[n1, n2-1] - V[n1, n2]) if n2 > 0 else 0)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def solve_MDP(model_pars):\n",
    "    # Unpacking\n",
    "    lam, mu, cores, p1, p2, alpha, M = model_pars\n",
    "    # We define old and new value function and update them.\n",
    "    old_V = np.full((M+1, M+1), 1.0, dtype=np.float64)\n",
    "    new_V = np.full((M+1, M+1), 1.0, dtype=np.float64)\n",
    "    # Change in old_V and new_V should eventually converge to average cost per unit time.\n",
    "    change_V = np.zeros((M+1, M+1))\n",
    "    # Stores optimal action\n",
    "    action = np.zeros((M+1, M+1))\n",
    "    \n",
    "    epsilon = 0.01 # Maximum permissible error\n",
    "    delta = math.inf\n",
    "    \n",
    "    iteration = 1\n",
    "    \n",
    "    while delta >= epsilon:\n",
    "        fraction_change = 1\n",
    "        for i in range(M+1):\n",
    "            for j in range(M+1):\n",
    "                term_1 = A(model_pars, [i,j], old_V)\n",
    "                term_2, a = H_and_action(model_pars, [i,j], old_V)\n",
    "                action[i,j] = a\n",
    "                new_V[i,j] = term_1 + float(term_2)\n",
    "                fraction_change = max(fraction_change, (new_V[i,j] - old_V[i,j])/old_V[i,j] if old_V[i,j] > 0 else 1)\n",
    "        change_V = new_V.copy() - old_V.copy()\n",
    "        delta = change_V.max() - change_V.min()\n",
    "        # print(\"Iteration = \", iteration, \" Delta = \", delta)\n",
    "        old_V = new_V.copy()\n",
    "        iteration += 1\n",
    "        \n",
    "    return new_V, action\n",
    "\n",
    "\n",
    "def bellman_optimal_policy(pars):\n",
    "    # Unpacking\n",
    "    lam, mu, cores, p1, p2, alpha, M = pars\n",
    "    # Scaling\n",
    "    model_pars = scale_pars(pars)\n",
    "    # Optimal value function and optimal policy\n",
    "    V_optimal, pi_optimal  = solve_MDP(model_pars)\n",
    "    relative_V_optimal = V_optimal - V_optimal[0,0]\n",
    "    # Calculate relative Q values\n",
    "    relative_Q_optimal = np.zeros((M+1, M+1, cores+1))\n",
    "    for i in range(M+1):\n",
    "        for j in range(M+1):\n",
    "            for k in range(cores+1):\n",
    "                probs = transition_probabilities(model_pars, [i,j], k/cores)\n",
    "                future_cost = 0\n",
    "                future_cost += probs[0]*relative_V_optimal[i+1, j] if i < M else 0\n",
    "                future_cost += probs[1]*relative_V_optimal[i, j+1] if j < M else 0\n",
    "                future_cost += probs[2]*relative_V_optimal[i-1, j] if i > 0 else 0\n",
    "                future_cost += probs[3]*relative_V_optimal[i, j-1] if j > 0 else 0\n",
    "                future_cost += probs[4]*relative_V_optimal[i, j]\n",
    "                relative_Q_optimal[i, j, k] = (i+j) + future_cost\n",
    "    \n",
    "    return pi_optimal, relative_V_optimal, relative_Q_optimal\n",
    "\n",
    "\n",
    "def scale_pars(pars):\n",
    "    lam = pars[0]\n",
    "    mu = pars[1]\n",
    "    cores = pars[2]\n",
    "    p1 = pars[3]\n",
    "    p2 = pars[4]\n",
    "    alpha = pars[5]\n",
    "    M = pars[6]\n",
    "    \n",
    "    scaling_factor = lam + M*mu*(speed_up(p1, cores) + speed_up(p2, cores))\n",
    "    scaled_pars = [lam/scaling_factor, mu/scaling_factor, cores, p1, p2, alpha, M]\n",
    "\n",
    "    return scaled_pars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9509895-78b3-4b82-a017-0692048a57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters\n",
    "lam = 2 # Arrival rate\n",
    "mu = 1 # Mean service time\n",
    "cores = 20 # Total number of cores\n",
    "p1 = 0.4 # Bad jobs (p1 should be lower than p2)\n",
    "p2 = 0.9 \n",
    "alpha = 0.2\n",
    "M = 10\n",
    "\n",
    "true_pars = [lam, mu, cores, p1, p2, alpha, M]\n",
    "\n",
    "bellman_pi_optimal, bellman_relative_V_optimal, bellman_relative_Q_optimal = bellman_optimal_policy(true_pars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7312582-aea6-43fa-8556-2e83b252556e",
   "metadata": {},
   "source": [
    "## Computing optimal actions given $\\lambda, p_1, p_2, \\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d083435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing\n",
    "# # print(\"Optimal actions are \")\n",
    "# # print(\"\")\n",
    "# # print(np.matrix.round(bellman_pi_optimal,3))\n",
    "\n",
    "# # Policy 1 heatmap\n",
    "# fig, axes = plt.subplots(figsize=(18, 15))\n",
    "# heatmap = sns.heatmap(bellman_pi_optimal, ax=axes, cmap=\"coolwarm\", annot=False, cbar=True)\n",
    "\n",
    "# # Move x-axis to top\n",
    "# axes.xaxis.set_ticks_position('top')\n",
    "# axes.xaxis.set_label_position('top')\n",
    "\n",
    "# # Grid coordinate labels\n",
    "# for i in range(bellman_pi_optimal.shape[0]):\n",
    "#     for j in range(bellman_pi_optimal.shape[1]):\n",
    "#         axes.text(j + 0.5, i + 0.5, f\"{bellman_pi_optimal[i][j]}\", ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# heatmap.collections[0].colorbar.set_label(\"Fraction to $n_1$ (Bad Jobs)\")\n",
    "# axes.set_title(\"Heatmap of Bellman Optimal Policy\", pad=30)\n",
    "# axes.set_xlabel(\"$n_2$ (Good jobs)\")\n",
    "# axes.set_ylabel(\"$n_1$ (Bad Jobs)\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45ed857-b5e1-476a-acfc-6aaa689603be",
   "metadata": {},
   "source": [
    "## Visualizing Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56237bcd-87f9-4bf3-8b9a-fc8e8ecb04e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage for action k=0\n",
    "# plot_q_heatmap(bellman_relative_Q_optimal, cores, action = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca72e79-c9a3-4972-a765-ba9486e2930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage for action k=0\n",
    "# plot_q_surface(bellman_relative_Q_optimal, cores, action = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c620dd-9262-443d-8221-5696dc2899e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage for state (i=5, j=5)\n",
    "# plot_q_vs_actions(bellman_relative_Q_optimal, state = [2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
