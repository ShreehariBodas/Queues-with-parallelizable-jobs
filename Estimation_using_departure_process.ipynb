{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a259b9c5-a1f3-4be9-ba06-1e466e79fdc1",
   "metadata": {},
   "source": [
    "## Estimating $p_1, p_2$ in queues with parallelizable jobs\n",
    "\n",
    "###\n",
    "### Jobs with inherent sizes distributed according to $\\text{Exp}(\\mu)$ arrive at rate $\\lambda$ to a system with $c$ cores.\n",
    "### Incoming jobs belong to type 1 or 2 (known) with speed-up $s_1(.)$ or $s_2(.)$ parameterized by $p_1, p_2$\n",
    "### Estimation is based on the knowledge that inter-departure times are distributed according to a NHPP\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1e8e28-a7f3-4383-8ecb-187fd758a5fa",
   "metadata": {},
   "source": [
    "## Preliminary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447fbc80-8374-44c9-b740-e60f9bfca2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.optimize import fsolve, minimize\n",
    "from scipy.integrate import quad\n",
    "from scipy import linspace, meshgrid, arange, empty, concatenate, newaxis, shape\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d5c875-8d83-4907-9ded-21d88d28dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_service_times(mu, n):\n",
    "    service_times = np.random.exponential(1/mu, n)\n",
    "    return service_times\n",
    "\n",
    "def generate_arrival_times(lam, n):\n",
    "    interarrival_times = np.random.exponential(1/lam, n-1)\n",
    "    arrival_times = np.append([0], np.cumsum(interarrival_times))\n",
    "    return arrival_times\n",
    "\n",
    "def generate_job_categories(alpha, n):\n",
    "    job_categories = np.ones(n) + np.random.binomial(1, alpha, n)\n",
    "    return job_categories\n",
    "\n",
    "def allocate_cores(total_cores, n_jobs):\n",
    "# This function should come from a learning process\n",
    "# For now, we assume a simple allocation policy so we can study estimation\n",
    "    if n_jobs[0] == 0 and n_jobs[1] == 0:\n",
    "        return np.array([0, 0])\n",
    "    elif n_jobs[0] == 0:\n",
    "        return np.array([0, total_cores])\n",
    "    elif n_jobs[1] == 0:\n",
    "        return np.array([total_cores, 0])\n",
    "    else:\n",
    "        fraction = n_jobs[0]/(n_jobs[0] + n_jobs[1])\n",
    "        allocation = np.array([fraction*total_cores, (1-fraction)*total_cores])\n",
    "    return allocation\n",
    "\n",
    "def speed_up(amdahl_par, n_cores):\n",
    "    speed_up = 1/(1 - amdahl_par*(1 - 1/max(1, n_cores)))\n",
    "    return speed_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f649974d-d479-4473-a2b8-702a7f55b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Job:\n",
    "    # Essential characteristics of each job which we would like to track\n",
    "    def __init__(self):\n",
    "        self.identity = 0\n",
    "        self.category = int(0)\n",
    "        self.arrival_time = 0\n",
    "        self.departure_time = 0\n",
    "        self.service_time = 0\n",
    "        self.residual_service_time = 0\n",
    "        self.history = [] # List of 2-tuple elements (speed, time at that speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b803ee-e769-4b78-98a9-e4ce06413f8b",
   "metadata": {},
   "source": [
    "## Simulation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc0849e-eeea-4e5f-89bb-575a62fabeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queue_simulation(amdahl_pars, model_pars, n, arrival_times, service_times, job_categories):\n",
    "    \n",
    "    # Unpack model variables\n",
    "    lam = model_pars[0]\n",
    "    mu = model_pars[1]\n",
    "    total_cores = model_pars[2]\n",
    "    alpha = model_pars[3]\n",
    "    \n",
    "    # Preprocessing\n",
    "    jobs = [Job() for i in range(n)]\n",
    "    for i in range(n):\n",
    "        jobs[i].identity = i\n",
    "        jobs[i].category = job_categories[i]\n",
    "        jobs[i].arrival_time = arrival_times[i]\n",
    "        jobs[i].service_time = service_times[i]\n",
    "        jobs[i].residual_service_time = service_times[i]\n",
    "    \n",
    "    ##############################################################################################################################################################\n",
    "    \n",
    "    # Data required for future\n",
    "    events = [] # List of 3-element tuples (Time, Arrival/Departure, Job id)\n",
    "    n_jobs_in_system_just_after_events = [] # List of 2-element tuples (Number of Type 1 jobs, Number of Type 2 jobs)\n",
    "    core_allocation_just_after_events = [] # List of 2-element tuples (Number of Type 1 cores, Number of Type 2 cores)\n",
    "    \n",
    "    # Simulation variables\n",
    "    job_ids_in_system = [] # Dynamic list which stores indices of jobs in system at any given time \n",
    "    arrived_job_id = -1\n",
    "    departed_job_id = -1\n",
    "    event = 'arrival'\n",
    "    n_jobs_in_system = np.zeros(2)\n",
    "    current_core_allocation = np.zeros(2)\n",
    "    current_core_allocation_per_job = np.zeros(2)\n",
    "    \n",
    "    current_time = 0\n",
    "    time_until_next_arrival = 0\n",
    "    time_until_next_departure = 0\n",
    "    time_until_next_event = 0\n",
    "    speed_up_values = np.zeros(2)\n",
    "    \n",
    "    ##############################################################################################################################################################\n",
    "    \n",
    "    # Queue simulation\n",
    "    while arrived_job_id < n-1:\n",
    "        if event == 'arrival':\n",
    "            arrived_job_id += 1 \n",
    "            events.append([current_time, 'arrival', arrived_job_id])\n",
    "            job_ids_in_system.append(arrived_job_id) # Appends arrived job id to the list of jobs in system\n",
    "            n_jobs_in_system[int(jobs[arrived_job_id].category)-1] += 1\n",
    "        else:\n",
    "            events.append([current_time, 'departure', departed_job_id])\n",
    "            job_ids_in_system.remove(departed_job_id) # Removes departed job id from list of jobs in system\n",
    "            n_jobs_in_system[int(jobs[departed_job_id].category)-1] -= 1\n",
    "        \n",
    "        n_jobs_in_system_just_after_events.append(n_jobs_in_system.copy())\n",
    "        current_core_allocation = allocate_cores(total_cores, n_jobs_in_system)\n",
    "        core_allocation_just_after_events.append(current_core_allocation)\n",
    "        current_core_allocation_per_job = np.array([current_core_allocation[j]/n_jobs_in_system[j] if n_jobs_in_system[j] !=0 else 0 for j in range(2)])\n",
    "        \n",
    "        if arrived_job_id != n-1:\n",
    "            # Time until next arrival\n",
    "            time_until_next_arrival = arrival_times[arrived_job_id + 1] - current_time\n",
    "            # Time until next departure\n",
    "            if job_ids_in_system == []:\n",
    "                time_until_next_departure = math.inf\n",
    "            else:\n",
    "                speed_up_values[0] = speed_up(amdahl_pars[0], current_core_allocation_per_job[0])\n",
    "                speed_up_values[1] = speed_up(amdahl_pars[1], current_core_allocation_per_job[1])\n",
    "                expected_times_until_departure = np.array([jobs[i].residual_service_time/speed_up_values[int(jobs[i].category)-1] for i in job_ids_in_system])\n",
    "                time_until_next_departure = np.min(expected_times_until_departure)\n",
    "            # Time until next event\n",
    "            if time_until_next_arrival > time_until_next_departure:\n",
    "                event = 'departure'\n",
    "                time_until_next_event = time_until_next_departure\n",
    "                departed_job_id = job_ids_in_system[np.argmin(expected_times_until_departure)]\n",
    "                jobs[departed_job_id].departure_time = current_time + time_until_next_event\n",
    "            else:\n",
    "                event = 'arrival'\n",
    "                time_until_next_event = time_until_next_arrival\n",
    "            \n",
    "            # Updating system state at time of next event\n",
    "            for job_id in job_ids_in_system:\n",
    "                jobs[job_id].residual_service_time -= speed_up_values[int(jobs[job_id].category)-1] * time_until_next_event\n",
    "                state = [speed_up_values[int(jobs[job_id].category)-1], time_until_next_event]\n",
    "                jobs[job_id].history.append(list(state))\n",
    "            \n",
    "            current_time += time_until_next_event\n",
    "    \n",
    "    return [jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42c99d7-6e6b-4aca-9ff4-f88c30334b81",
   "metadata": {},
   "source": [
    "## Dataset generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c71fc3-bbe3-4578-979d-664c9385294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(amdahl_pars, model_pars, n):\n",
    "    arrival_times = generate_arrival_times(lam, n)\n",
    "    service_times = generate_service_times(mu, n)\n",
    "    job_categories = generate_job_categories(alpha, n)\n",
    "    \n",
    "    dataset = queue_simulation(amdahl_pars, model_pars, n, arrival_times, service_times, job_categories)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d538c55b-52c6-446a-9916-2660088ff019",
   "metadata": {},
   "source": [
    "## Estimation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beee351-4c1a-4278-add3-10e9c56a13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Log_Likelihood(amdahl_pars, model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events):\n",
    "    # print(amdahl_pars)\n",
    "    \n",
    "    lam = model_pars[0]\n",
    "    mu = model_pars[1]\n",
    "    total_cores = model_pars[2]\n",
    "    alpha = model_pars[3]\n",
    "    \n",
    "    LL = 0\n",
    "    \n",
    "    # For parameter p_1\n",
    "    start_event_index = 0\n",
    "    end_event_index = 0\n",
    "    \n",
    "    while end_event_index < len(events):\n",
    "        # Calculate start index, end index for parameter p_1\n",
    "        # Corresponds basically to an inter-departure time barring edge cases\n",
    "        \n",
    "        # Start index calculation        \n",
    "        start_event_index = end_event_index\n",
    "        while start_event_index < len(events) - 1 and n_jobs_in_system_just_after_events[start_event_index][0] == 0:\n",
    "            start_event_index += 1\n",
    "        if start_event_index >= len(events) - 1:\n",
    "            break\n",
    "        # End index calculation\n",
    "        flag = 0\n",
    "        end_event_index = start_event_index\n",
    "        while end_event_index + 1 < len(events):\n",
    "            end_event_index += 1\n",
    "            if events[end_event_index][1] == 'departure' and jobs[events[end_event_index][2]].category == 1:\n",
    "                flag = 1\n",
    "                break\n",
    "        # print(\"Type 1 job (Start index, Start time) = \", [start_event_index, events[start_event_index][0]], \" (End index, End time) = \", [end_event_index, events[end_event_index][0]])\n",
    "        \n",
    "        # Log Likelihood component corresponding to this inter-departure time\n",
    "        core_allocation_per_job = 0\n",
    "        for i in range(start_event_index, end_event_index):\n",
    "                core_allocation_per_job = core_allocation_just_after_events[i][0]/n_jobs_in_system_just_after_events[i][0] if n_jobs_in_system_just_after_events[i][0] !=0 else 0\n",
    "                LL += -mu * n_jobs_in_system_just_after_events[i][0] * speed_up(amdahl_pars[0], core_allocation_per_job) * (events[i+1][0] - events[i][0])\n",
    "        if flag == 1: # If flag = 0, event is just that during some time, number of departures are 0.\n",
    "            LL += np.log(n_jobs_in_system_just_after_events[end_event_index - 1][0]) + np.log(speed_up(amdahl_pars[0], core_allocation_per_job))\n",
    "        \n",
    "    # For parameter p_2\n",
    "    start_event_index = 0\n",
    "    end_event_index = 0\n",
    "    \n",
    "    while end_event_index < len(events):\n",
    "        # Calculate start index, end index for parameter p_2\n",
    "        # Corresponds basically to an inter-departure time barring edge cases\n",
    "        \n",
    "        # Start index calculation        \n",
    "        start_event_index = end_event_index\n",
    "        while start_event_index < len(events) - 1 and n_jobs_in_system_just_after_events[start_event_index][1] == 0:\n",
    "            start_event_index += 1\n",
    "        if start_event_index >= len(events) - 1:\n",
    "            break\n",
    "        # End index calculation\n",
    "        flag = 0\n",
    "        end_event_index = start_event_index\n",
    "        while end_event_index + 1 < len(events):\n",
    "            end_event_index += 1\n",
    "            if events[end_event_index][1] == 'departure' and jobs[events[end_event_index][2]].category == 2:\n",
    "                flag = 1\n",
    "                break\n",
    "        # print(\"Type 2 job (Start index, Start time) = \", [start_event_index, events[start_event_index][0]], \" (End index, End time) = \", [end_event_index, events[end_event_index][0]])\n",
    "        \n",
    "        # Log Likelihood component corresponding to this inter-departure time\n",
    "        core_allocation_per_job = 0\n",
    "        for i in range(start_event_index, end_event_index):\n",
    "                core_allocation_per_job = core_allocation_just_after_events[i][1]/n_jobs_in_system_just_after_events[i][1] if n_jobs_in_system_just_after_events[i][1] !=0 else 0\n",
    "                LL += -mu * n_jobs_in_system_just_after_events[i][1] * speed_up(amdahl_pars[1], core_allocation_per_job) * (events[i+1][0] - events[i][0])\n",
    "        if flag == 1: # If flag = 0, event is just that during some time, number of departures are 0.\n",
    "            LL += np.log(n_jobs_in_system_just_after_events[end_event_index - 1][1]) + np.log(speed_up(amdahl_pars[1], core_allocation_per_job))\n",
    "    \n",
    "    return -LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e42e5b9-3b66-4341-9579-a44ea878d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimation(model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events):\n",
    "    # Initial Estimates\n",
    "    initial_estimates = np.array([0.5, 0.5])\n",
    "    # Bounds\n",
    "    amdahl_par_bounds = [(0.001, 0.999), (0.001, 0.999)]\n",
    "    # Estimation\n",
    "    estd_amdahl_pars = minimize(Log_Likelihood, initial_estimates, method = \"Nelder-Mead\", args = (model_pars, jobs, job_ids_in_system, events, n_jobs_in_system_just_after_events, core_allocation_just_after_events), bounds = amdahl_par_bounds)\n",
    "    return estd_amdahl_pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed46f69-c5af-4502-8f5d-d841c57b32d6",
   "metadata": {},
   "source": [
    "## Main function - Executes entire algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c95b639-e26f-430e-99d2-dc77b1776e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_algorithm_1(amdahl_pars, model_pars, n):\n",
    "# Estimation based on the departure process = algorithm 1\n",
    "    dataset = generate_dataset(amdahl_pars, model_pars, n)\n",
    "    estd_amdahl_pars = estimation(model_pars, *dataset)\n",
    "    print(\"True parameters = \", amdahl_pars)\n",
    "    print(\"Estimated parameters = \", estd_amdahl_pars.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e964c43-4e7a-4285-9093-ec84800addd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True parameters =  [0.4, 0.75]\n",
      "Estimated parameters =  [0.4059023  0.76528049]\n"
     ]
    }
   ],
   "source": [
    "lam = 10\n",
    "mu = 1\n",
    "total_cores = 20\n",
    "p_1 = 0.40\n",
    "p_2 = 0.75\n",
    "alpha = 0.5\n",
    "\n",
    "amdahl_pars = [p_1, p_2]\n",
    "model_pars = [lam, mu, total_cores, alpha]\n",
    "\n",
    "n = 10000\n",
    "\n",
    "execute_algorithm_1(amdahl_pars, model_pars, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ee32d-fea9-4c8f-8065-237c51fe5938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495d13e-b207-495f-a856-16652fd27934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86934137-430c-4a91-8495-0b6bb1ee0ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9cfd80-3dc4-40ce-80fd-64bfdd144ba7",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804fb31f-e442-45fd-9548-b12c05f8ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing some stuff   \n",
    "    \n",
    "print(\"Number of jobs just after event times\")\n",
    "print(\"\")\n",
    "for i in range(len(n_jobs_in_system_just_after_events)):\n",
    "    print(\"Index = \", i, \" , Time = \", np.round(events[i][0],3), \" ,Type 1 = \", int(n_jobs_in_system_just_after_events[i][0]), \", Type 2 = \", int(n_jobs_in_system_just_after_events[i][1]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301114c3-0ea0-4cfa-9605-5c4948450679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether inherent size as calculated from job history equates to true size.\n",
    "\n",
    "for job in jobs:\n",
    "    calculated_job_size = 0\n",
    "    for state in job.history:\n",
    "        calculated_job_size += state[0]*state[1]\n",
    "    print(\"Calculated job size = \", calculated_job_size, \" , True job size = \", job.service_time)\n",
    "    \n",
    "# NOTE: For some of the jobs at the end, calculated and true job sizes will not match.\n",
    "# This is because they have not yet departed from system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee346290-b032-4dc0-9258-0274446972bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All jobs at one point had the same history. Fixed the issue now.\n",
    "\n",
    "print(jobs[0].history == jobs[99].history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
